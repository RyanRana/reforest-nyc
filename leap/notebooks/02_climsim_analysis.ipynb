{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ClimSim Dataset Analysis\n",
        "\n",
        "Deep dive into the ClimSim low-resolution dataset from Hugging Face.\n",
        "\n",
        "## About ClimSim\n",
        "\n",
        "ClimSim is a large-scale climate simulation dataset designed for training machine learning emulators. It contains:\n",
        "- **Inputs**: Atmospheric state variables (temperature, humidity, etc.) at multiple vertical levels\n",
        "- **Outputs**: Physical tendencies (how variables change over time)\n",
        "- **Goal**: Train ML models to predict climate physics faster than traditional simulators\n",
        "\n",
        "**Dataset:** [LEAP/ClimSim_low-res](https://huggingface.co/datasets/LEAP/ClimSim_low-res)\n",
        "\n",
        "**Prerequisites:** Run `leap_startup.ipynb` first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Hugging Face\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid' if 'seaborn-v0_8-darkgrid' in plt.style.available else 'default')\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load ClimSim Dataset\n",
        "\n",
        "We'll load a small subsample first to understand the structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "repo_id = \"LEAP/ClimSim_low-res\"\n",
        "\n",
        "print(f\"Loading ClimSim dataset from: {repo_id}\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load a small subset first (streaming mode to avoid downloading everything)\n",
        "# We'll take just 1000 samples to analyze\n",
        "try:\n",
        "    dataset = load_dataset(\n",
        "        repo_id,\n",
        "        split=\"train[:1000]\",  # Load first 1000 samples\n",
        "        streaming=False  # Download this subset fully for analysis\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Successfully loaded {len(dataset)} samples!\\n\")\n",
        "    print(f\"Dataset info:\")\n",
        "    print(f\"  - Number of samples: {len(dataset)}\")\n",
        "    print(f\"  - Features: {list(dataset.features.keys())}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading dataset: {e}\")\n",
        "    print(\"\\nNote: This might fail if:\")\n",
        "    print(\"  1. The dataset structure is different than expected\")\n",
        "    print(\"  2. You need to accept the dataset terms on Hugging Face\")\n",
        "    print(\"  3. The dataset requires authentication\")\n",
        "    \n",
        "    # Create synthetic data for demonstration\n",
        "    print(\"\\nüìù Creating synthetic ClimSim-like data for demonstration...\")\n",
        "    \n",
        "    # Typical ClimSim structure\n",
        "    n_samples = 1000\n",
        "    n_levels = 60  # Vertical levels\n",
        "    \n",
        "    # Input variables (atmospheric state)\n",
        "    state_t = np.random.randn(n_samples, n_levels) * 30 + 250  # Temperature (K)\n",
        "    state_q0001 = np.random.randn(n_samples, n_levels) * 0.002 + 0.005  # Specific humidity\n",
        "    state_ps = np.random.randn(n_samples) * 5000 + 100000  # Surface pressure (Pa)\n",
        "    \n",
        "    # Output variables (tendencies)\n",
        "    ptend_t = np.random.randn(n_samples, n_levels) * 0.1  # Temperature tendency\n",
        "    ptend_q0001 = np.random.randn(n_samples, n_levels) * 1e-6  # Humidity tendency\n",
        "    \n",
        "    # Create dictionary mimicking ClimSim structure\n",
        "    dataset = {\n",
        "        'state_t': state_t,\n",
        "        'state_q0001': state_q0001,\n",
        "        'state_ps': state_ps,\n",
        "        'ptend_t': ptend_t,\n",
        "        'ptend_q0001': ptend_q0001,\n",
        "    }\n",
        "    \n",
        "    print(\"‚úÖ Synthetic dataset created for demonstration\")\n",
        "    print(\"   (Replace with real data loading above when available)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inspect Data Structure\n",
        "\n",
        "Let's examine the shapes and types of inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert dataset to numpy arrays for inspection\n",
        "if hasattr(dataset, '__getitem__') and hasattr(dataset, 'features'):\n",
        "    # HuggingFace dataset\n",
        "    first_sample = dataset[0]\n",
        "    \n",
        "    # Separate input (state) and output (ptend) variables\n",
        "    input_vars = {k: v for k, v in first_sample.items() if k.startswith('state_')}\n",
        "    output_vars = {k: v for k, v in first_sample.items() if k.startswith('ptend_')}\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"INPUT VARIABLES (Atmospheric State)\")\n",
        "    print(\"=\" * 70)\n",
        "    for var_name in sorted(input_vars.keys()):\n",
        "        var_data = np.array([dataset[i][var_name] for i in range(len(dataset))])\n",
        "        print(f\"{var_name:20s} shape: {str(var_data.shape):20s} dtype: {var_data.dtype}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"OUTPUT VARIABLES (Physical Tendencies)\")\n",
        "    print(\"=\" * 70)\n",
        "    for var_name in sorted(output_vars.keys()):\n",
        "        var_data = np.array([dataset[i][var_name] for i in range(len(dataset))])\n",
        "        print(f\"{var_name:20s} shape: {str(var_data.shape):20s} dtype: {var_data.dtype}\")\n",
        "    \n",
        "    # Store for later use\n",
        "    data_dict = {}\n",
        "    for key in list(input_vars.keys()) + list(output_vars.keys()):\n",
        "        data_dict[key] = np.array([dataset[i][key] for i in range(len(dataset))])\n",
        "        \n",
        "else:\n",
        "    # Synthetic dictionary\n",
        "    data_dict = dataset\n",
        "    \n",
        "    input_vars = {k: v for k, v in data_dict.items() if k.startswith('state_')}\n",
        "    output_vars = {k: v for k, v in data_dict.items() if k.startswith('ptend_')}\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"INPUT VARIABLES (Atmospheric State)\")\n",
        "    print(\"=\" * 70)\n",
        "    for var_name in sorted(input_vars.keys()):\n",
        "        print(f\"{var_name:20s} shape: {str(input_vars[var_name].shape):20s} dtype: {input_vars[var_name].dtype}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"OUTPUT VARIABLES (Physical Tendencies)\")\n",
        "    print(\"=\" * 70)\n",
        "    for var_name in sorted(output_vars.keys()):\n",
        "        print(f\"{var_name:20s} shape: {str(output_vars[var_name].shape):20s} dtype: {output_vars[var_name].dtype}\")\n",
        "\n",
        "print(\"\\nüí° Interpretation:\")\n",
        "print(\"  - state_* variables: Current atmospheric conditions (inputs)\")\n",
        "print(\"  - ptend_* variables: How variables change over time (outputs/targets)\")\n",
        "print(\"  - Vertical dimension: Multiple atmospheric levels (surface to top)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Variable Details\n",
        "\n",
        "ClimSim typically includes these variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variable_descriptions = {\n",
        "    # Input variables (state)\n",
        "    'state_t': 'Temperature [K] at each vertical level',\n",
        "    'state_q0001': 'Specific humidity [kg/kg] - water vapor',\n",
        "    'state_q0002': 'Cloud liquid water [kg/kg]',\n",
        "    'state_q0003': 'Cloud ice [kg/kg]',\n",
        "    'state_u': 'Zonal wind [m/s] - eastward component',\n",
        "    'state_v': 'Meridional wind [m/s] - northward component',\n",
        "    'state_ps': 'Surface pressure [Pa] - single value per column',\n",
        "    \n",
        "    # Output variables (tendencies)\n",
        "    'ptend_t': 'Temperature tendency [K/s] - rate of temperature change',\n",
        "    'ptend_q0001': 'Specific humidity tendency [kg/kg/s]',\n",
        "    'ptend_q0002': 'Cloud liquid water tendency [kg/kg/s]',\n",
        "    'ptend_q0003': 'Cloud ice tendency [kg/kg/s]',\n",
        "    'ptend_u': 'Zonal wind tendency [m/s¬≤]',\n",
        "    'ptend_v': 'Meridional wind tendency [m/s¬≤]',\n",
        "}\\n\n",
        "print(\"=\" * 70)\n",
        "print(\"VARIABLE DESCRIPTIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "present_vars = list(data_dict.keys())\n",
        "\n",
        "print(\"\\nüìä INPUT VARIABLES (State):\")\n",
        "for var, desc in variable_descriptions.items():\n",
        "    if var.startswith('state_') and var in present_vars:\n",
        "        print(f\"  ‚úÖ {var:15s} - {desc}\")\n",
        "    elif var.startswith('state_'):\n",
        "        print(f\"  ‚ö™ {var:15s} - {desc} (not in this dataset)\")\n",
        "\n",
        "print(\"\\nüìà OUTPUT VARIABLES (Tendencies):\")\n",
        "for var, desc in variable_descriptions.items():\n",
        "    if var.startswith('ptend_') and var in present_vars:\n",
        "        print(f\"  ‚úÖ {var:15s} - {desc}\")\n",
        "    elif var.startswith('ptend_'):\n",
        "        print(f\"  ‚ö™ {var:15s} - {desc} (not in this dataset)\")\n",
        "\n",
        "print(f\"\\nüìã Total variables in dataset: {len(present_vars)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Vertical Levels\n",
        "\n",
        "Climate models use vertical levels to represent the atmosphere from surface to top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine number of vertical levels\n",
        "for var_name in sorted(input_vars.keys()):\n",
        "    if len(data_dict[var_name].shape) == 2:  # 2D array (samples, levels)\n",
        "        n_samples, n_levels = data_dict[var_name].shape\n",
        "        break\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"VERTICAL STRUCTURE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Number of samples:        {n_samples}\")\n",
        "print(f\"Number of vertical levels: {n_levels}\")\n",
        "print(f\"\\nüí° Vertical levels typically represent:\")\n",
        "print(f\"   - Level 0:  Top of atmosphere (~0-10 hPa)\")\n",
        "print(f\"   - Level {n_levels//2}: Mid-troposphere (~500 hPa)\")\n",
        "print(f\"   - Level {n_levels-1}: Near surface (~1000 hPa)\")\n",
        "print(f\"\\n   (Lower pressure = higher altitude)\")\n",
        "\n",
        "# Create approximate pressure levels (typical for climate models)\n",
        "# These are hybrid sigma-pressure coordinates\n",
        "if n_levels == 60:\n",
        "    # Typical 60-level configuration\n",
        "    pressure_levels = np.linspace(10, 1000, n_levels)  # hPa (mb)\n",
        "elif n_levels == 30:\n",
        "    pressure_levels = np.linspace(50, 1000, n_levels)\n",
        "else:\n",
        "    pressure_levels = np.linspace(100, 1000, n_levels)\n",
        "\n",
        "print(f\"\\nApproximate pressure levels (hPa):\")\n",
        "print(f\"   Top (level 0):    {pressure_levels[0]:.1f} hPa\")\n",
        "print(f\"   Middle:           {pressure_levels[n_levels//2]:.1f} hPa\")\n",
        "print(f\"   Bottom (level {n_levels-1}): {pressure_levels[-1]:.1f} hPa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sample Statistics\n",
        "\n",
        "Compute mean and standard deviation for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute statistics for all variables\n",
        "print(\"=\" * 70)\n",
        "print(\"SAMPLE STATISTICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nüìä INPUT VARIABLES (State):\")\n",
        "print(f\"{'Variable':<20} {'Mean':>15} {'Std':>15} {'Min':>15} {'Max':>15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for var_name in sorted(input_vars.keys()):\n",
        "    data = data_dict[var_name]\n",
        "    mean_val = np.mean(data)\n",
        "    std_val = np.std(data)\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    \n",
        "    print(f\"{var_name:<20} {mean_val:>15.6f} {std_val:>15.6f} {min_val:>15.6f} {max_val:>15.6f}\")\n",
        "\n",
        "print(\"\\nüìà OUTPUT VARIABLES (Tendencies):\")\n",
        "print(f\"{'Variable':<20} {'Mean':>15} {'Std':>15} {'Min':>15} {'Max':>15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for var_name in sorted(output_vars.keys()):\n",
        "    data = data_dict[var_name]\n",
        "    mean_val = np.mean(data)\n",
        "    std_val = np.std(data)\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    \n",
        "    print(f\"{var_name:<20} {mean_val:>15.9f} {std_val:>15.9f} {min_val:>15.9f} {max_val:>15.9f}\")\n",
        "\n",
        "print(\"\\nüí° Notes on statistics:\")\n",
        "print(\"  - Input variables: Represent physical atmospheric state\")\n",
        "print(\"  - Output tendencies: Typically much smaller (rates of change)\")\n",
        "print(\"  - These statistics are crucial for normalization in ML training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Check for Pre-Applied Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if data appears normalized\n",
        "print(\"=\" * 70)\n",
        "print(\"NORMALIZATION CHECK\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nChecking if data is pre-normalized (mean~0, std~1)...\\n\")\n",
        "\n",
        "def check_normalization(data, var_name):\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    \n",
        "    # Check if close to standard normal\n",
        "    is_normalized = (abs(mean) < 0.5 and 0.5 < std < 1.5)\n",
        "    \n",
        "    status = \"‚úÖ Likely normalized\" if is_normalized else \"‚ö™ Not normalized (raw data)\"\n",
        "    print(f\"{var_name:<20} mean={mean:>8.3f}, std={std:>8.3f}  {status}\")\n",
        "    \n",
        "    return is_normalized\n",
        "\n",
        "print(\"INPUT VARIABLES:\")\n",
        "input_normalized = []\n",
        "for var_name in sorted(input_vars.keys()):\n",
        "    is_norm = check_normalization(data_dict[var_name], var_name)\n",
        "    input_normalized.append(is_norm)\n",
        "\n",
        "print(\"\\nOUTPUT VARIABLES:\")\n",
        "output_normalized = []\n",
        "for var_name in sorted(output_vars.keys()):\n",
        "    is_norm = check_normalization(data_dict[var_name], var_name)\n",
        "    output_normalized.append(is_norm)\n",
        "\n",
        "if any(input_normalized) or any(output_normalized):\n",
        "    print(\"\\n‚úÖ Some variables appear pre-normalized\")\n",
        "    print(\"   You may not need additional normalization for ML training\")\n",
        "else:\n",
        "    print(\"\\n‚ö™ Variables appear to be raw (not normalized)\")\n",
        "    print(\"   You should normalize before ML training:\")\n",
        "    print(\"   - Standardization: (x - mean) / std\")\n",
        "    print(\"   - Min-max scaling: (x - min) / (max - min)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization: Temperature Vertical Profile\n",
        "\n",
        "Visualize temperature as a function of height for a single atmospheric column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get temperature data\n",
        "temp_data = data_dict['state_t']\n",
        "\n",
        "# Select a random column to visualize\n",
        "sample_idx = np.random.randint(0, temp_data.shape[0])\n",
        "temp_profile = temp_data[sample_idx, :]\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 10))\n",
        "\n",
        "# Plot temperature vs pressure (height proxy)\n",
        "ax.plot(temp_profile, pressure_levels, 'b-', linewidth=2, marker='o', markersize=4)\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('Temperature (K)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Pressure (hPa)', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'Vertical Temperature Profile\\\\nSample #{sample_idx}', \n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Invert y-axis (pressure decreases with height)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# Add grid\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add annotations\n",
        "ax.axhline(y=500, color='r', linestyle='--', alpha=0.5, label='~500 hPa (mid-troposphere)')\n",
        "ax.axhline(y=200, color='orange', linestyle='--', alpha=0.5, label='~200 hPa (upper troposphere)')\n",
        "\n",
        "# Add freezing point reference\n",
        "if temp_profile.min() < 273.15 < temp_profile.max():\n",
        "    # Find approximate altitude where temp = 273.15K\n",
        "    freezing_idx = np.argmin(np.abs(temp_profile - 273.15))\n",
        "    ax.axvline(x=273.15, color='cyan', linestyle=':', alpha=0.7, label='Freezing point (273.15 K)')\n",
        "    ax.plot(273.15, pressure_levels[freezing_idx], 'c*', markersize=15)\n",
        "\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "\n",
        "# Add text with statistics\n",
        "stats_text = f'Mean: {np.mean(temp_profile):.2f} K\\\\nStd: {np.std(temp_profile):.2f} K\\\\nMin: {np.min(temp_profile):.2f} K\\\\nMax: {np.max(temp_profile):.2f} K'\n",
        "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
        "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
        "        fontsize=9, family='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\\\n‚úÖ Visualized temperature profile for sample #{sample_idx}\")\n",
        "print(f\"   Temperature range: {temp_profile.min():.2f} - {temp_profile.max():.2f} K\")\n",
        "print(f\"   Vertical levels: {len(temp_profile)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualization: Temperature Tendency Profile\n",
        "\n",
        "Visualize how temperature changes over time (the target variable for ML prediction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get temperature tendency data\n",
        "temp_tend_data = data_dict['ptend_t']\n",
        "\n",
        "# Use same sample as before for consistency\n",
        "temp_tend_profile = temp_tend_data[sample_idx, :]\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 10))\n",
        "\n",
        "# Plot tendency vs pressure\n",
        "ax.plot(temp_tend_profile, pressure_levels, 'r-', linewidth=2, marker='s', markersize=4)\n",
        "\n",
        "# Add zero line\n",
        "ax.axvline(x=0, color='k', linestyle='-', alpha=0.3, linewidth=1)\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('Temperature Tendency (K/s)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Pressure (hPa)', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'Vertical Temperature Tendency Profile\\\\nSample #{sample_idx}', \n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Invert y-axis\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# Add grid\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add shading for cooling/warming\n",
        "warming_mask = temp_tend_profile > 0\n",
        "cooling_mask = temp_tend_profile < 0\n",
        "\n",
        "if np.any(warming_mask):\n",
        "    ax.fill_betweenx(pressure_levels, 0, temp_tend_profile, \n",
        "                      where=warming_mask, alpha=0.2, color='red', label='Warming')\n",
        "if np.any(cooling_mask):\n",
        "    ax.fill_betweenx(pressure_levels, 0, temp_tend_profile, \n",
        "                      where=cooling_mask, alpha=0.2, color='blue', label='Cooling')\n",
        "\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "\n",
        "# Add statistics box\n",
        "stats_text = f'Mean: {np.mean(temp_tend_profile):.2e} K/s\\\\nStd: {np.std(temp_tend_profile):.2e} K/s\\\\nMin: {np.min(temp_tend_profile):.2e} K/s\\\\nMax: {np.max(temp_tend_profile):.2e} K/s'\n",
        "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
        "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5),\n",
        "        fontsize=9, family='monospace')\n",
        "\n",
        "# Add interpretation text\n",
        "interp_text = 'Positive: Heating\\\\nNegative: Cooling\\\\n\\\\nPhysical processes:\\\\n‚Ä¢ Radiation\\\\n‚Ä¢ Convection\\\\n‚Ä¢ Cloud formation'\n",
        "ax.text(0.98, 0.02, interp_text, transform=ax.transAxes, \n",
        "        verticalalignment='bottom', horizontalalignment='right',\n",
        "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5),\n",
        "        fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\\\n‚úÖ Visualized temperature tendency for sample #{sample_idx}\")\n",
        "print(f\"   Tendency range: {temp_tend_profile.min():.2e} - {temp_tend_profile.max():.2e} K/s\")\n",
        "print(f\"   Mean tendency: {np.mean(temp_tend_profile):.2e} K/s\")\n",
        "print(f\"\\\\nüí° Interpretation:\")\n",
        "print(f\"   - Positive values: Warming (heating from radiation, convection)\")\n",
        "print(f\"   - Negative values: Cooling (radiative cooling, evaporation)\")\n",
        "print(f\"   - Goal of ML emulator: Predict these tendencies from state variables\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Multi-Variable Comparison\n",
        "\n",
        "Compare input state and output tendency for multiple variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create side-by-side comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
        "\n",
        "# Left plot: Input state variables\n",
        "ax = axes[0]\n",
        "if 'state_t' in data_dict:\n",
        "    ax.plot(data_dict['state_t'][sample_idx], pressure_levels, 'b-', label='Temperature (K)', linewidth=2)\n",
        "\n",
        "if 'state_q0001' in data_dict:\n",
        "    # Scale humidity for visibility\n",
        "    q_scaled = data_dict['state_q0001'][sample_idx] * 1000  # g/kg\n",
        "    ax2 = ax.twiny()\n",
        "    ax2.plot(q_scaled, pressure_levels, 'g--', label='Specific humidity (g/kg)', linewidth=2)\n",
        "    ax2.set_xlabel('Specific Humidity (g/kg)', fontsize=11, color='g')\n",
        "    ax2.tick_params(axis='x', labelcolor='g')\n",
        "\n",
        "ax.set_xlabel('Temperature (K)', fontsize=11, color='b')\n",
        "ax.set_ylabel('Pressure (hPa)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Input: Atmospheric State', fontsize=13, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.tick_params(axis='x', labelcolor='b')\n",
        "\n",
        "# Right plot: Output tendencies\n",
        "ax = axes[1]\n",
        "if 'ptend_t' in data_dict:\n",
        "    ax.plot(data_dict['ptend_t'][sample_idx] * 3600, pressure_levels,  # Convert to K/hour\n",
        "             'r-', label='Temp. tendency (K/hr)', linewidth=2)\n",
        "\n",
        "if 'ptend_q0001' in data_dict:\n",
        "    # Scale humidity tendency for visibility\n",
        "    q_tend_scaled = data_dict['ptend_q0001'][sample_idx] * 3600 * 1000  # g/kg/hr\n",
        "    ax2 = ax.twiny()\n",
        "    ax2.plot(q_tend_scaled, pressure_levels, 'm--', label='Humidity tendency', linewidth=2)\n",
        "    ax2.set_xlabel('Humidity Tendency (g/kg/hr)', fontsize=11, color='m')\n",
        "    ax2.tick_params(axis='x', labelcolor='m')\n",
        "\n",
        "ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "ax.set_xlabel('Temperature Tendency (K/hr)', fontsize=11, color='r')\n",
        "ax.set_ylabel('Pressure (hPa)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Output: Physical Tendencies', fontsize=13, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.tick_params(axis='x', labelcolor='r')\n",
        "\n",
        "plt.suptitle(f'ClimSim Data Analysis - Sample #{sample_idx}', \n",
        "             fontsize=15, fontweight='bold', y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\n‚úÖ Multi-variable comparison complete!\")\n",
        "print(\"\\\\nüí° Machine Learning Task:\")\n",
        "print(\"   INPUT:  Atmospheric state (temperature, humidity, etc.)\")\n",
        "print(\"   OUTPUT: Physical tendencies (how state changes)\")\n",
        "print(\"   GOAL:   Train neural network to predict tendencies from state\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Next Steps\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Data Structure**: ClimSim contains atmospheric columns with vertical profiles\n",
        "2. **Inputs**: State variables (temperature, humidity, winds, etc.)\n",
        "3. **Outputs**: Tendencies (rates of change) to be predicted\n",
        "4. **Vertical Levels**: Multiple atmospheric layers from surface to top\n",
        "5. **Statistics**: Ranges and distributions of each variable\n",
        "6. **Normalization**: Whether data is pre-normalized or needs preprocessing\n",
        "\n",
        "### Next Steps for ML Emulator\n",
        "\n",
        "1. **Data Preprocessing**\n",
        "   - Normalize/standardize variables\n",
        "   - Handle missing values\n",
        "   - Create train/validation/test splits\n",
        "   \n",
        "2. **Model Architecture**\n",
        "   - Design neural network (MLP, CNN, or Transformer)\n",
        "   - Consider physical constraints\n",
        "   - Account for vertical structure\n",
        "   \n",
        "3. **Training**\n",
        "   - Define loss function (MSE, MAE, or physics-informed)\n",
        "   - Use JAX/Flax for efficient training\n",
        "   - Monitor validation metrics\n",
        "   \n",
        "4. **Evaluation**\n",
        "   - Compare predictions vs targets\n",
        "   - Check physical consistency\n",
        "   - Test on unseen data\n",
        "\n",
        "### Resources\n",
        "\n",
        "- **ClimSim Paper**: [Link to paper if available]\n",
        "- **Hugging Face Dataset**: https://huggingface.co/datasets/LEAP/ClimSim_low-res\n",
        "- **LEAP Documentation**: Check hackathon materials\n",
        "\n",
        "Good luck building your climate emulator! üåçüöÄ"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
